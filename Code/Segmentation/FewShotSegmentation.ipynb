{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch albumentations grad-cam gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ca9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import gdown\n",
    "\n",
    "import re\n",
    "\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils as smp_utils\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54e514",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip Dataset\n",
    "data_folder = \"ISVC_Segmentation\"\n",
    "DATA = \"/home/datascience/ISVC_2023_Tutorial_XAI_Few_Shot_on_the_Cloud/SampleDataset(s)/\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAVE_DIR = \"checkpoints/\"\n",
    "SHOT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98388a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA, data_folder)):\n",
    "    with ZipFile(f\"{DATA}/{data_folder}.zip\", 'r') as zipf:\n",
    "        zipf.extractall(f\"{DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def generate_datasets(root_dir, image_dir, annot_dir,  task=\"localization\"):\n",
    "    img_dir = os.path.join(root_dir, image_dir)\n",
    "    annot_dir = os.path.join(root_dir, annot_dir)\n",
    "    \n",
    "    # PID regex\n",
    "    pid_reg = re.compile(\"9[0-9]{6}\")\n",
    "    \n",
    "    # Image names + annotation names match\n",
    "    records = [[pid_reg.findall(img)[-1], img, img if task != \"localization\" else img.replace(\".jpg\", \".xml\")] \n",
    "               for img in os.listdir(img_dir) if \".DS_Store\" not in img and \".ipynb_checkpoints\" not in img]\n",
    "\n",
    "    data_records = pd.DataFrame(records, columns=[\"pid\", \"images\", \"masks\"])\n",
    "\n",
    "    train, test = train_test_split(data_records.pid.unique(), test_size=0.5, random_state=42)\n",
    "    valid, test = train_test_split(test, test_size=0.5, random_state=42)\n",
    "\n",
    "    train = data_records[data_records.pid.isin(train)].reset_index(drop=True)\n",
    "    valid = data_records[data_records.pid.isin(valid)].reset_index(drop=True)\n",
    "    test = data_records[data_records.pid.isin(test)].reset_index(drop=True)\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = generate_datasets(f\"{DATA}/{data_folder}\", \"Images\", \"Labels\", task=\"segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_few_shot_sample(dataset, k=1, random_state=42):\n",
    "    if k > len(dataset):\n",
    "        return dataset\n",
    "\n",
    "    return dataset.sample(k, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_few = get_few_shot_sample(train, k=SHOT)\n",
    "valid_few = get_few_shot_sample(valid, k=SHOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_dir = \"/home/datascience/ISVC_2023_Tutorial_XAI_Few_Shot_on_the_Cloud/SampleDataset(s)/Few_Shot/Segmentation\"\n",
    "if not os.path.exists(few_shot_dir):\n",
    "    os.makedirs(few_shot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438920b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{few_shot_dir}/{SHOT}-shot/train/images\")\n",
    "os.makedirs(f\"{few_shot_dir}/{SHOT}-shot/train/labels\")\n",
    "\n",
    "os.makedirs(f\"{few_shot_dir}/{SHOT}-shot/valid/images\")\n",
    "os.makedirs(f\"{few_shot_dir}/{SHOT}-shot/valid/labels\")\n",
    "\n",
    "os.makedirs(f\"{few_shot_dir}/{SHOT}-shot/test/images\")\n",
    "os.makedirs(f\"{few_shot_dir}/{SHOT}-shot/test/labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ebe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in train_few.images:\n",
    "    shutil.copy(f\"{DATA}/{data_folder}/Images/{pid}\", f\"{few_shot_dir}/{SHOT}-shot/train/images/{pid}\")\n",
    "    shutil.copy(f\"{DATA}/{data_folder}/Annotations/{pid}\", f\"{few_shot_dir}/{SHOT}-shot/train/labels/{pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49055cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in valid_few.images:\n",
    "    shutil.copy(f\"{DATA}/{data_folder}/Images/{pid}\", f\"{few_shot_dir}/{SHOT}-shot/valid/images/{pid}\")\n",
    "    shutil.copy(f\"{DATA}/{data_folder}/Annotations/{pid}\", f\"{few_shot_dir}/{SHOT}-shot/valid/labels/{pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in test.images:\n",
    "    shutil.copy(f\"{DATA}/{data_folder}/Images/{pid}\", f\"{few_shot_dir}/{SHOT}-shot/test/images/{pid}\")\n",
    "    shutil.copy(f\"{DATA}/{data_folder}/Annotations/{pid}\", f\"{few_shot_dir}/{SHOT}-shot/test/labels/{pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72891fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointSpaceSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_root, mask_root, image_files, mask_files, transforms=None, preprocessing=None):\n",
    "        self.img_root = img_root\n",
    "        self.mask_root = mask_root\n",
    "        self.img_files = image_files\n",
    "        self.mask_files = mask_files\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(os.path.join(self.img_root, self.img_files[idx])))\n",
    "        mask = np.array(Image.open(os.path.join(self.mask_root, self.mask_files[idx])))\n",
    "\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        mask = torch.unsqueeze(mask, 0)\n",
    "        if self.preprocessing is not None:\n",
    "            transformed = self.preprocessing(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "        return image.type(torch.FloatTensor), mask/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_ROOT = f\"{few_shot_dir}/{SHOT}-shot/\"\n",
    "train_augmentations = A.Compose([A.Resize(256, 256), A.Rotate(15), A.RandomBrightness(0.2),\n",
    "                                 A.RandomContrast(0.2),  ToTensorV2()])\n",
    "\n",
    "test_augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()])\n",
    "\n",
    "train_set = JointSpaceSegmentationDataset(os.path.join(FEW_SHOT_ROOT, \"train/images\"),\n",
    "                                          os.path.join(FEW_SHOT_ROOT, \"train/labels\"),\n",
    "                                          train_few.images, train_few.masks,\n",
    "                                          preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
    "                                          transforms=train_augmentations)\n",
    "\n",
    "valid_set = JointSpaceSegmentationDataset(os.path.join(FEW_SHOT_ROOT, \"valid/images\"),\n",
    "                                          os.path.join(FEW_SHOT_ROOT, \"valid/labels\"),\n",
    "                                          valid_few.images, valid_few.masks,\n",
    "                                          preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
    "                                          transforms=test_augmentations)\n",
    "\n",
    "test_set = JointSpaceSegmentationDataset(os.path.join(FEW_SHOT_ROOT, \"test/images\"),\n",
    "                                         os.path.join(FEW_SHOT_ROOT, \"test/labels\"),\n",
    "                                         test.images, test.masks,\n",
    "                                         preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
    "                                         transforms=test_augmentations)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd9207",
   "metadata": {},
   "source": [
    "## Sample Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Augmentations\n",
    "img_pth = \"/home/datascience/ISVC_2023_Tutorial_XAI_Few_Shot_on_the_Cloud/SampleDataset(s)/ISVC_Segmentation/Images/9975485L.png\"\n",
    "mask_pth = \"/home/datascience/ISVC_2023_Tutorial_XAI_Few_Shot_on_the_Cloud/SampleDataset(s)/ISVC_Segmentation/Annotations/9975485L.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51776888",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_pth)\n",
    "mask = cv2.imread(mask_pth)\n",
    "\n",
    "augA = A.Rotate(35)\n",
    "augB = A.RandomBrightness(0.4)\n",
    "augC = A.RandomContrast(0.4)\n",
    "\n",
    "augA_out = augA(image=img, mask=mask, prob=1)\n",
    "augB_out = augB(image=img, mask=mask, prob=1)\n",
    "augC_out = augC(image=img, mask=mask, prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(10, 10))\n",
    "axs[0, 0].imshow(img)\n",
    "axs[0, 1].imshow(mask)\n",
    "axs[0, 0].set_title(\"Image\")\n",
    "axs[0, 1].set_title(\"Mask\")\n",
    "axs[1, 0].imshow(augA_out[\"image\"])\n",
    "axs[1, 1].imshow(augA_out[\"mask\"])\n",
    "axs[1, 0].set_title(\"Image Rotation\")\n",
    "axs[1, 1].set_title(\"Mask\")\n",
    "axs[2, 0].imshow(augB_out[\"image\"])\n",
    "axs[2, 1].imshow(augB_out[\"mask\"])\n",
    "axs[2, 0].set_title(\"Image Brightness\")\n",
    "axs[2, 1].set_title(\"Mask\")\n",
    "axs[3, 0].imshow(augC_out[\"image\"])\n",
    "axs[3, 1].imshow(augC_out[\"mask\"])\n",
    "axs[3, 0].set_title(\"Image Contrast\")\n",
    "axs[3, 1].set_title(\"Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d150edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b185145",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = \"resnet18\"\n",
    "encoder_weights = \"imagenet\"\n",
    "activation = \"sigmoid\"\n",
    "num_classes = 1 # 0=background, 1=joint space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd13d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model = copy.deepcopy(smp.Unet(encoder_name=encoder, encoder_weights=encoder_weights, in_channels=1,\n",
    "                 classes=num_classes, activation=activation))\n",
    "model.encoder.requires_grad_ = True\n",
    "model = model.to(DEVICE)\n",
    "loss = nn.BCELoss()\n",
    "loss.__name__=\"loss\"\n",
    "metrics = [smp_utils.metrics.IoU(threshold=0.5, activation=None), smp_utils.metrics.Fscore(0.5, activation=None)]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_set, batch_size=2, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee69e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners\n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for i in range(1, 101):\n",
    "\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['fscore']:\n",
    "        max_score = valid_logs['fscore']\n",
    "        torch.save(model, f'{SAVE_DIR}/best_model_{SHOT}_shot.pth')\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179747da",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a446319",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
    "test_img, test_mask  = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'{SAVE_DIR}/best_model_{SHOT}_shot.pth') # map_location=torch.device(DEVICE))\n",
    "\n",
    "avg_iou = 0.0\n",
    "avg_fscore = 0.0\n",
    "iou_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
    "fscore_metric = smp.utils.metrics.Fscore(threshold=0.5)\n",
    "for img, mask in test_loader:\n",
    "    out = model(img.to(DEVICE))\n",
    "    mask = mask.to(DEVICE)\n",
    "    avg_iou += iou_metric(out, mask).item()\n",
    "    avg_fscore += fscore_metric(out, mask).item()\n",
    "\n",
    "print(f\"Test IoU: {avg_iou/len(test_loader)}\\nTest Dice Score: {avg_fscore/len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(10, 10), sharex=True, sharey=True)\n",
    "fig.suptitle(f\"Few-Shot Segmentation Results (K = {SHOT})\")\n",
    "for i, (img, mask) in enumerate(test_loader):\n",
    "    ax[i, 0].imshow(img[0][0,:,:].squeeze(),cmap=\"gray\")\n",
    "    ax[i, 0].set_title(\"X-Ray\")\n",
    "    ax[i, 1].imshow(mask.squeeze())\n",
    "    ax[i, 1].set_title(\"Mask\")\n",
    "    ax[i, 2].imshow(torch.sigmoid(model(img.to(DEVICE)).squeeze().detach().cpu()).numpy())\n",
    "    ax[i, 2].set_title(\"Predicted Mask\")\n",
    "\n",
    "    if (i + 1) == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b513ec",
   "metadata": {},
   "source": [
    "## Comparing Different K-Shot Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac835d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(id=\"1jG7jTAMKLMEcfQOa1EAhwmsPTh0PdPy9\", output=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b65cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./ISVC_Seg_Checkpoints.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_iou = []\n",
    "few_dice = []\n",
    "\n",
    "for shot in [1, 3, 5, 7, 10]:\n",
    "    generate_datasets(f\"{DATA}/{data_folder}\", \"Images\", \"Labels\", task=\"segmentation\")\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = torch.load(f'{SAVE_DIR}/best_model_{shot}_shot.pth', map_location=torch.device(DEVICE))\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "\n",
    "    avg_iou = 0.0\n",
    "    avg_fscore = 0.0\n",
    "    iou_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
    "    fscore_metric = smp.utils.metrics.Fscore(threshold=0.5)\n",
    "    for img, mask in test_loader:\n",
    "        out = model(img.to(DEVICE))\n",
    "        mask = mask.to(DEVICE)\n",
    "        avg_iou += iou_metric(out, mask).item()\n",
    "        avg_fscore += fscore_metric(out, mask).item()\n",
    "    few_iou.append(avg_iou/len(test_loader))\n",
    "    few_dice.append(avg_fscore/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687432f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1, 3, 5, 7, 10], few_iou)\n",
    "plt.plot([1, 3, 5, 7, 10], few_dice)\n",
    "plt.xlabel(\"K-Shot\")\n",
    "plt.ylabel(\"IoU/Dice Score\")\n",
    "plt.title(\"K-Shot IoU vs. Dice Score\")\n",
    "plt.legend([\"IoU\", \"Dice Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2b6c2",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16234edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shot = 10 # Change to compare to pretrained checkpoints\n",
    "model = torch.load(f'{SAVE_DIR}/best_model_{shot}_shot.pth', map_location=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCamSampler(nn.Module):\n",
    "    def __init__(self, img_root, mask_root, image_files, mask_files, transforms=None, preprocessing=None, samples_to_generate=5):\n",
    "        self.img_root = img_root\n",
    "        self.mask_root = mask_root\n",
    "        self.img_files = image_files\n",
    "        self.mask_files = mask_files\n",
    "        self.samples_to_generate = samples_to_generate\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def _sample_images_for_gradcam(self):\n",
    "        sample_ids = np.random.choice(range(len(self.img_files)), size=self.samples_to_generate)\n",
    "        self.ids = sample_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples_to_generate\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(os.path.join(self.img_root, self.img_files[idx])))\n",
    "        mask = np.array(Image.open(os.path.join(self.mask_root, self.mask_files[idx])))\n",
    "\n",
    "        # image = np.stack([image, image, image], axis=-1)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        # mask = torch.unsqueeze(mask, 0)\n",
    "\n",
    "        if self.preprocessing is not None:\n",
    "            transformed = self.preprocessing(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "            # mask = transformed[\"mask\"]\n",
    "\n",
    "        return image.type(torch.FloatTensor), mask/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cd3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()])\n",
    "\n",
    "test_set = GradCamSampler(os.path.join(FEW_SHOT_ROOT, \"test/images\"),\n",
    "                                         os.path.join(FEW_SHOT_ROOT, \"test/labels\"),\n",
    "                                         test.images, test.masks,\n",
    "                                         preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
    "                                         transforms=test_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b79858",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
    "test_img, test_mask  = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationTarget:\n",
    "    def __init__(self, category, mask):\n",
    "        self.category = category\n",
    "        if type(mask) == np.array:\n",
    "            self.mask = torch.from_numpy(mask)\n",
    "        else:\n",
    "            self.mask = mask\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.mask = self.mask.cuda()\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        print(self.mask.shape == model_output.shape)\n",
    "        return (model_output[self.category,:,:] * self.mask).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ae16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.decoder, model.segmentation_head]\n",
    "iou = smp_utils.metrics.IoU(threshold=0.5)\n",
    "\n",
    "with GradCAM(model=model,\n",
    "             target_layers=target_layers,\n",
    "             use_cuda=torch.cuda.is_available()) as cam:\n",
    "\n",
    "    fig, ax = plt.subplots(len(test_loader), 4, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "    for i, (test_img, test_mask) in enumerate(test_loader):\n",
    "        targets = [SemanticSegmentationTarget(0, test_mask)]\n",
    "\n",
    "        grayscale_cam = cam(input_tensor=test_img,\n",
    "                            targets=targets)[0, :]\n",
    "\n",
    "        test_img2= test_img.squeeze().squeeze().detach().cpu().numpy()/255.0\n",
    "        test_img2 = np.stack([test_img2, test_img2, test_img2], axis=-1)\n",
    "\n",
    "        cam_image = show_cam_on_image(test_img2, grayscale_cam, use_rgb=True)\n",
    "        out = model(test_img.to(DEVICE))\n",
    "\n",
    "        ax[i, 0].imshow(test_img[0][0,:,:].squeeze(),cmap=\"gray\")\n",
    "        ax[i, 0].set_title(\"X-Ray\")\n",
    "        ax[i, 1].imshow(test_mask.squeeze())\n",
    "        ax[i, 1].set_title(\"Mask\")\n",
    "        ax[i, 2].imshow(torch.sigmoid(out).squeeze().detach().cpu().numpy())\n",
    "        ax[i, 2].set_title(\"Predicted Mask\")\n",
    "        ax[i, 3].imshow(Image.fromarray(cam_image))\n",
    "        ax[i, 3].set_title(\"Grad-CAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
